name: Scrape Display Board

on:
  schedule:
    - cron: '35 4 * * *'   # Morning 10:05 AM IST (4:35 AM UTC) - targets 10:25 AM with delay
    - cron: '40 8 * * *'    # Afternoon 2:30 PM IST (9:00 AM UTC) - targets 2:30 PM with delay
  workflow_dispatch:
    inputs:
      job_type:
        description: 'Which scrape job to run'
        required: true
        type: choice
        options:
          - morning
          - afternoon
          - both
        default: 'morning'

jobs:
  morning-scrape:
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '35 4 * * *') ||
      (github.event_name == 'workflow_dispatch' && (inputs.job_type == 'morning' || inputs.job_type == 'both'))
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run morning scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/display_board_scraper.py
        
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: morning-scrape-logs
          path: "*.log"
          if-no-files-found: ignore

  afternoon-scrape:
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '0 9 * * *') ||
      (github.event_name == 'workflow_dispatch' && (inputs.job_type == 'afternoon' || inputs.job_type == 'both'))
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run afternoon scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python scripts/display_board_scraper.py
        
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: afternoon-scrape-logs
          path: "*.log"
          if-no-files-found: ignore
